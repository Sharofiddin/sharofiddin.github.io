<!DOCTYPE html>
<html>
<head>
<link rel="Stylesheet" type="text/css" href="style.css">
<link rel="alternate" type="application/rss+xml" title="RSS" href="rss.xml">
<link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" />
<title>DesigningDataIntensiveApplications</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
</head>
<body>

<div id="Overall"><h1 id="Overall" class="header"><a href="#Overall">Overall</a></h1></div>
<p>
Book focuses on these key concerns:
</p>
<ul>
<li>
Reliability

<li>
Scalability

<li>
Maintainability

</ul>
<p>
Data models:
</p>
<ul>
<li>
Relational

<li>
Document

<li>
Graph

</ul>
  
<p>
Storage engines:
</p>
<ul>
<li>
Log structured

<li>
Page oriented

</ul>
 
<p>
 Logs in general - append-only sequence of records.
 Pros:
</p>
<ul>
<li>
Fast read(with in-memory hashmap index)/write

<li>
Recovery. No update - no possibility of mixture of old data and new data in one record.

<li>
No fragmented files if merge used.

</ul>
<p>
Cons:
</p>
<ul>
<li>
Very large number of keys causes huge RAM consumption.

<li>
Range queries are not effective. If values for keys between <code>key10</code> and <code>key99</code> are requested for each key value will be fetched.

</ul>
<div id="Overall-Indexes"><h2 id="Indexes" class="header"><a href="#Overall-Indexes">Indexes</a></h2></div>
<p>
Index types:
</p>
<ul>
<li>
LSMTree(Log Structured Merge Tree)

<li>
B-Tree(Balanced Tree)

</ul>
<p>
B-Tree:
</p>
<ul>
<li>
B-Tree uses pages (or blocks) to store keys, references and values.

<li>
WAL (Write-Ahead-Log) used for crash recovery.

<li>
Reference count in one page named <code>branching factor</code>

<li>
Abbrevating keys saves space and causes high *<span id="Overall-Indexes-branching factor"></span><strong id="branching factor">branching factor</strong>*, so fewer levels, and this makes search faster.

</ul>
<p>
<code>Write amplification</code> - one write to database causes multiple writes.
</p>

<p>
LSMTree vs B-Tree:
</p>
<ul>
<li>
LSMTree faster write, it has lower <code>write amplification</code> than B-Tree. When B-Tree page fill it will be splitted to two new pages, and parent page keeps references to new children. This causes higher write amplification.

</ul>
<p>
...
</p>

<p>
Index has key and value. Key is the thing queries search for. For example ID, or name (if indexed). But value can be :
</p>
<ol>
<li>
actual row(document in mongodb, vertex in neo4j)

<li>
reference to the row(document, vertex) stored elsewhere.

</ol>
<p>
In second case, place that rows are stored is known as a <code>heap file</code>. Heap file is good to keep changes in one place. But when referenced heap location changed all indexes should be updated to point new location.
If indexed row directly stored with row (first case) it named <code>clustered index</code>
Other indexing structures:
</p>
<ul>
<li>
multi-column indexes (R-Tree).
  ...

</ul>
<p>
NVM - Non-volatile memory.
</p>

<div id="Replication"><h1 id="Replication" class="header"><a href="#Replication">Replication</a></h1></div>

<p>
Why we replicate data:
</p>
<ul>
<li>
To keep data geographically close to users.

<li>
To allow system to operate when some of its parts failed.

<li>
To scale out the number of machines that can serve to read queries (increase throughput)
 <span id="Replication-Popular replicating algorithms:"></span><strong id="Popular replicating algorithms:">Popular replicating algorithms:</strong>

<li>
single-leader

<li>
multi-leader

<li>
leaderless

</ul>
<div id="Replication-Leader based replication"><h2 id="Leader based replication" class="header"><a href="#Replication-Leader based replication">Leader based replication</a></h2></div>

<p>
When we replicate database, every write should processed by every replica to avoid data inconsistency between replicas. <span id="Replication-Leader based replication-Leader based replication"></span><strong id="Leader based replication">Leader based replication</strong> or <em>master-slave replication</em> is the most common solution for it.
It works as follows:
</p>
<ol>
<li>
One of the replicas is designated as <em>leader</em> (master/primary). Clients sends write requests to the leader. Leader first writes the new data to its local storage.

<li>
The other replicas are knows as <em>followers (read replicas, slaves, secondaries, or hot standbys)</em>. Whenever the leader writes new data to its local storage, it also sends the data change to all of its followers as part of a <em>replication log</em> or <em>change stream</em>. Each follower takes the log from the leader and updates it local copy of the DB accordingly, by applying all writes in the same order as they were processed on the leader

<li>
When client initiates read request it can be served by on of the standbys or leader. But, writes are only accepted on the leader. The followers are read-only from the client's point of view.

</ol>
<div id="Replication-Synchronous vs Asynchronous replication"><h2 id="Synchronous vs Asynchronous replication" class="header"><a href="#Replication-Synchronous vs Asynchronous replication">Synchronous vs Asynchronous replication</a></h2></div>

<p>
  Whether replication happens synchronously or asynchronously is important detail of replicated system. In relational database it is usually configurable option; in other systems it is often hardcoded.
Let's say we have one <span id="Replication-Synchronous vs Asynchronous replication-leader"></span><strong id="leader">leader</strong> and two <span id="Replication-Synchronous vs Asynchronous replication-replicas"></span><strong id="replicas">replicas</strong> for user management system. At some point in time, client requests <span id="Replication-Synchronous vs Asynchronous replication-the leader"></span><strong id="the leader">the leader</strong> to update some user's profile image. Request recieved by the leaeder after short time it was sent. At some point, the leader forwards data change to followers. Eventually, the leader notifies the client that the update was successfull. What happens if the leader sends update to the first replica synchronously and to the second asynchronously? The leader waits the first replica's confirmation about recieving the update successfully before notifying to the client, but no second's. 
  Usually, replication is fast (less than a second). But there is no guarante of how long it takes. It take several minutes in some cases: when replica is recovering from failuer, network problems between nodes, OS near maximum capacity. In these cases, asynchronously replicated follower may fall behind the leader by several minutes. On the otherhand, the synchronously replicated follower will block the leader from finishing the operation.
  Synchronous replication:
</p>
<ul>
<li>
Advantages:

<ul>
<li>
Up to date data with the Leader. Even, if the leader fails, all successfully written data is still available on the follower.

</ul>
<li>
Disadvantages:

<ul>
<li>
If the follower does not respond (crashed, network error,...), the write can not be processed. The leader must block all writes until the synchronous is available again.
  For this shortcoming, it is impractical to make all followers synchronous: If one of them fallen, the whole system stops operating. In practice: One of the followers is made synchronous. If synchronous followers fails or slows down, one of the asynchronous followers is made synchronous and we alwasy have two nodes with <em>up to date</em> data: The leader and the synchronous follower. This configuration sometimes called <em>semi-synchronous</em>.

</ul>
</ul>
  
<div id="Replication-Adding new followers"><h2 id="Adding new followers" class="header"><a href="#Replication-Adding new followers">Adding new followers</a></h2></div>

<p>
  Adding new followers to the cluster is not always straight forward task. We can not just copy and paste leader's data into new replica server. Because during data transfer process the leader my accept new writes. Or, the leader should be locked until new replica gets all data. But we want to do it without downtime:
</p>
<ol>
<li>
Take a consistent snapshot of the leader's database at some point in time-, if possible, without taking a lock on entire database. Most databases have thi feature, as it also required for backups.

<li>
Copy the snapshot to the new follower node.

<li>
The follower connects to the leader and requests all the data changes since snapshot was taken.

<li>
When the follower has processed the backlog of data changes since snapshot, it is called <em>caught up</em>. Now, it can continue to process data changes from the leader as they happen.

</ol>
<p>
...
</p>

<div id="Replication-Problems with replication lag"><h2 id="Problems with replication lag" class="header"><a href="#Replication-Problems with replication lag">Problems with replication lag</a></h2></div>

<ul>
<li>
<em>read-after-write consistency</em> == <em>read-your-writes consistency</em> - it ensures that if user reloads the page, they will always see any updates they submitted themselves, no promise about other user's update.

<li>
<em>monotonic reads</em> - let's say we have one leader and two replicas, user_1 added new comment, user_2 read this comment from replica_1, but when he refreshed page comment disappeared because this time user_2 read data from replica_2 which has not updated data yet. Monotonic reads guarantees that there is nothis kind of situation, by routing each user to exact datacenter whenever he reads data.

<li>
<em>consistent prefix reads</em> ...

</ul>
<div id="Replication-Multi-Leader replication"><h2 id="Multi-Leader replication" class="header"><a href="#Replication-Multi-Leader replication">Multi-Leader replication</a></h2></div>

<p>
  In single-leader replication if app can not connect to the leader it can not write to the database. If we have more than one leader connection problem with one leader won't stop us from writing to the database. It is called a <em>multi-leader</em> configuration. Also known as master-master or active/active replication. Each leader simultaneously acts as a follower to the other leaders.
</p>

<div id="Replication-Multi-Leader replication-Use cases for multi-leader replication"><h3 id="Use cases for multi-leader replication" class="header"><a href="#Replication-Multi-Leader replication-Use cases for multi-leader replication">Use cases for multi-leader replication</a></h3></div>

<div id="Replication-Multi-Leader replication-Use cases for multi-leader replication-Multi-datacenter operation"><h4 id="Multi-datacenter operation" class="header"><a href="#Replication-Multi-Leader replication-Use cases for multi-leader replication-Multi-datacenter operation">Multi-datacenter operation</a></h4></div>
  
<p>
  When we have single-leader setup with multiple datacenter, all writes go to the single leader, so any issue with leader's datacenter will stop all writes eventhough other datacenters operating normally, and synchronous replication can be serious bottleneck if sync-replica is in different datacenter from leader's. These issues of single-leader configuration dimnish advantages of multi-dataceneter setup.
  Advantages of multi-leader:
</p>
<ul>
<li>
Performance

<li>
Tolerance of datacenter outage

<li>
Tolerance of network problems
  Big Downside:

<li>
Concurrent update of data requires "conflict resolution".

</ul>
<div id="Replication-Multi-Leader replication-Use cases for multi-leader replication-Clients with offline operation"><h4 id="Clients with offline operation" class="header"><a href="#Replication-Multi-Leader replication-Use cases for multi-leader replication-Clients with offline operation">Clients with offline operation</a></h4></div>

<p>
  When application should work even it is disconnected from internet, multi-leader replication can be useful. Like calendar apps. Even your phone is offline you can see calendar and can mark some days for some events, when your gained access to the internet again your calendar reconsile its data with server. In this extreme case each device with your account is leader. 
</p>

<div id="Replication-Multi-Leader replication-Use cases for multi-leader replication-Collaborative editing"><h4 id="Collaborative editing" class="header"><a href="#Replication-Multi-Leader replication-Use cases for multi-leader replication-Collaborative editing">Collaborative editing</a></h4></div>

<p>
  <em>Real time collaborative editing</em> apps allow several people to edit a document simultaneously like Google Docs.
</p>
  
<div id="Replication-Multi-Leader replication-Handling Write Conflicts"><h3 id="Handling Write Conflicts" class="header"><a href="#Replication-Multi-Leader replication-Handling Write Conflicts">Handling Write Conflicts</a></h3></div>

<p>
...
</p>

<div id="Replication-Multi-Leader replication-Multi-Leader Replication Topologies"><h3 id="Multi-Leader Replication Topologies" class="header"><a href="#Replication-Multi-Leader replication-Multi-Leader Replication Topologies">Multi-Leader Replication Topologies</a></h3></div>

<p>
If Multi-Leader replication only has two leaders, it is trivial topology: both of them send writes to another and receive it. But when we have more than two Leaders, we have different topologies:
</p>
<ul>
<li>
circle

<li>
star

<li>
all-to-all

</ul>
<p>
In circle, each Leader nor recieves writes from one Leader node and sends writes (it's own and received from prior Leader) to other Leader.
In start topology, there is one Leader node which forwards all writes from other Leaders. It can be generalized to Tree topology.
All-to-all - each Leader sends writes to all other Leader nodes.
</p>

<p>
Cirlce and Star topologies are more prone to Single-Point-Of-failure.
All-to-all is fault tolerant but in ordering is complex problem in this topology.
</p>

<div id="Replication-Multi-Leader replication-Leaderless replication"><h3 id="Leaderless replication" class="header"><a href="#Replication-Multi-Leader replication-Leaderless replication">Leaderless replication</a></h3></div>

<div id="Replication-Multi-Leader replication-Leaderless replication-Writing to the Database When a Node Is Down"><h4 id="Writing to the Database When a Node Is Down" class="header"><a href="#Replication-Multi-Leader replication-Leaderless replication-Writing to the Database When a Node Is Down">Writing to the Database When a Node Is Down</a></h4></div>
<p>
  <em>n</em> - Replication Factor: In leaderless replication the replication factor n is the number of nodes to store a replica of particular pieco of data. Total number of nodes in cluster can be greater from <em>n</em>. In this case, read and write nodes may or may not be overlapped. 
</p>
<div id="Replication-Multi-Leader replication-Leaderless replication-Limitations of Quorum Consistency"><h4 id="Limitations of Quorum Consistency" class="header"><a href="#Replication-Multi-Leader replication-Leaderless replication-Limitations of Quorum Consistency">Limitations of Quorum Consistency</a></h4></div>
<p>
 <em>Anti-entropy</em> - background process that compares data between nodes and detects and fixes inconsistencies. It is proactive process which periodically runs. In contrast, <em>read-repair</em> is reactive process only checks inconsistencies when data accessed for read. 
</p>

<div id="Replication-Multi-Leader replication-Leaderless replication-Sloppy Quorums and Hinted Handoff"><h4 id="Sloppy Quorums and Hinted Handoff" class="header"><a href="#Replication-Multi-Leader replication-Leaderless replication-Sloppy Quorums and Hinted Handoff">Sloppy Quorums and Hinted Handoff</a></h4></div>

<div id="Replication-Multi-Leader replication-Leaderless replication-Detecting Concurrent Writes"><h4 id="Detecting Concurrent Writes" class="header"><a href="#Replication-Multi-Leader replication-Leaderless replication-Detecting Concurrent Writes">Detecting Concurrent Writes</a></h4></div>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
<script type="text/javascript">
    document.querySelectorAll('pre').forEach(block => hljs.highlightBlock(block));
</script>
</body>
</html>
